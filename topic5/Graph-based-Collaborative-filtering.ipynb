{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4748fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "# !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
    "# !pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "b32ad5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "b44359c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movie_path = './ml-latest-small/movies.csv'\n",
    "rating_path = './ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "db1244d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user and movie nodes\n",
    "def load_node_csv(path, index_col):\n",
    "    \"\"\"Loads csv containing node information\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        index_col (str): column name of index column\n",
    "\n",
    "    Returns:\n",
    "        dict: mapping of csv row to node id\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, index_col=index_col)\n",
    "    \n",
    "    # assign unique index for each user/movie\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    return mapping\n",
    "\n",
    "\n",
    "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
    "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "fe36f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edges between users and movies\n",
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        src_index_col (str): column name of users\n",
    "        src_mapping (dict): mapping between row number and user id\n",
    "        dst_index_col (str): column name of items\n",
    "        dst_mapping (dict): mapping between row number and item id\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    edge_index = None\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "\n",
    "    return torch.tensor(edge_index)\n",
    "\n",
    "\n",
    "edge_index = load_edge_csv(\n",
    "    rating_path,\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "3f11250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
    "num_interactions = edge_index.shape[1]\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=1)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices, test_size=0.5, random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "b0f7c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "0ef229e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4175a90",
   "metadata": {},
   "source": [
    "# Implementing NGCF\n",
    "\n",
    "## High-order Propagation in NGCF\n",
    "Between each layer, NGCF uses the following propagation rule for user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "e_u^{(k)} = LeakyReLU \\left(  m^{(k)}_{u \\leftarrow u}  + \\sum_{i\\in N_u}   m^{(k)}_{u \\leftarrow i} \\right)\\\\\n",
    "m^{(k)}_{u \\leftarrow u} = W_1^{(k)}e_u^{(k-1)},\\\\\n",
    "m^{(k)}_{u \\leftarrow i} = \\frac{1}{\\sqrt{|N_u||N_i|}} \\left( W_1^{(k)}e_i^{(k-1)} + W_2^{(k)} \\left( e_i^{(k-1)} \\odot e_u^{(k-1)} \\right)  \\right)\n",
    "\\end{equation}\n",
    "\n",
    "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
    "\n",
    "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
    "\n",
    "$e_u^{(k)}$ : k-th layer user embedding\n",
    "\n",
    "$e_i^{(k)}$ : k-th layer item embedding\n",
    "\n",
    "\n",
    "\n",
    "## Layer Combination and Model Prediction\n",
    "We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "e_u = e_u^{(0)} || \\cdots || e_u^{(K)} \\quad e_i = e_i^{(0)} || \\cdots || e_i^{(K)}\n",
    "\\end{equation}\n",
    "\n",
    "$||$ : denotes the concatenate operation\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}_{ui} = e_u^Te_i\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "f987b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines NGCF model\n",
    "class NGCF(MessagePassing):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes NGCF Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "        self.W1_list = nn.ModuleList([nn.Linear(self.embedding_dim,self.embedding_dim,bias=False) for _ in range(K)])\n",
    "        self.W2_list = nn.ModuleList([nn.Linear(self.embedding_dim,self.embedding_dim,bias=False) for _ in range(K)])\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of NGCF Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_i_k\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k, K=i) + self.W1_list[i](emb_k)\n",
    "            emb_k = F.leaky_relu(emb_k)\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        emb_final = torch.cat(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, items_emb_final\n",
    "\n",
    "    def message(self, x_i: Tensor, x_j: Tensor, K: int ) -> Tensor:\n",
    "        return self.W1_list[K](x_j) + self.W2_list[K](x_j * x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57e1f8",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "\n",
    "\n",
    "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
    "\n",
    "\\begin{equation}\n",
    "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
    "\\end{equation}\n",
    "\n",
    "$\\hat{y}_{u}$: predicted score of a positive sample\n",
    "\n",
    "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
    "\n",
    "$\\lambda$: hyperparameter which controls the L2 regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "38d4531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, pos_items_emb_final, neg_items_emb_final):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "    loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50a85c",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We evalaluate our model using the following metrics\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "p: a particular rank position\n",
    "\n",
    "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
    "\n",
    "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
    "\n",
    "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
    "\\end{equation}\n",
    "\n",
    "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "fffb4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "8fe36cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "54a08bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "eb3fcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(user_embedding, item_embedding, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "35863d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    #users_emb_final, items_emb_final = model.forward(sparse_edge_index)\n",
    "    users_emb_final, items_emb_final = model.users_emb.weight, model.items_emb.weight\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    \n",
    "    # indices\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final = users_emb_final[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        users_emb_final, items_emb_final, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e9e16",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Your test set performance should be in line with the following (*K=20*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "ef072d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "30fc7342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "model = NGCF(num_users, num_movies,embedding_dim=DIM)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# initialize parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=LAMBDA)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "d24d235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training loop\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# for iter in range(ITERATIONS):\n",
    "#     # forward propagation\n",
    "#     users_emb_final, items_emb_final = model.forward(\n",
    "#         train_sparse_edge_index)\n",
    "\n",
    "#     # mini batching\n",
    "#     user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "#         BATCH_SIZE, train_edge_index)\n",
    "#     user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "#         device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "#     users_emb_final = users_emb_final[user_indices]\n",
    "#     pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "#     neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "\n",
    "#     # loss computation\n",
    "#     train_loss = bpr_loss(users_emb_final, pos_items_emb_final, neg_items_emb_final)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     train_loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if iter % ITERS_PER_EVAL == 0:\n",
    "#         model.eval()\n",
    "#         val_loss, recall, precision, ndcg = evaluation(\n",
    "#             model, val_edge_index, val_sparse_edge_index, [train_edge_index], K)\n",
    "#         print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {train_loss.item():.4f}, val_loss: {val_loss:.4f}, val_recall@{K}: {recall:.4f}, val_precision@{K}: {precision:.4f}, val_ndcg@{K}: {ndcg:.4f}\")\n",
    "#         train_losses.append(train_loss.item())\n",
    "#         val_losses.append(val_loss)\n",
    "#         model.train()\n",
    "\n",
    "#     if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "cfd793e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "# plt.plot(iters, train_losses, label='train')\n",
    "# plt.plot(iters, val_losses, label='validation')\n",
    "# plt.xlabel('iteration')\n",
    "# plt.ylabel('loss')\n",
    "# plt.title('training and validation loss curves')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "9b8ecada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate on test set\n",
    "# model.eval()\n",
    "# test_edge_index = test_edge_index.to(device)\n",
    "# test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "# test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
    "#             model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K)\n",
    "\n",
    "# print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e3c0a",
   "metadata": {},
   "source": [
    "# Make New Recommendatios for a Given User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "0fdea58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "df = pd.read_csv(movie_path)\n",
    "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
    "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
    "\n",
    "user_pos_items = get_user_positive_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "33bbb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_predictions(user_id, num_recs):\n",
    "#     user = user_mapping[user_id]\n",
    "#     e_u = model.users_emb.weight[user]\n",
    "#     scores = model.items_emb.weight @ e_u\n",
    "\n",
    "#     values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "\n",
    "#     movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "#     movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "#     titles = [movieid_title[id] for id in movie_ids]\n",
    "#     genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "#     print(f\"Here are some movies that user {user_id} rated highly\")\n",
    "#     for i in range(num_recs):\n",
    "#         print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
    "\n",
    "#     print()\n",
    "\n",
    "#     movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "#     movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "#     titles = [movieid_title[id] for id in movie_ids]\n",
    "#     genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "#     print(f\"Here are some suggested movies for user {user_id}\")\n",
    "#     for i in range(num_recs):\n",
    "#         print(f\"title: {titles[i]}, genres: {genres[i]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "17e3f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER_ID = 6\n",
    "# NUM_RECS = 4\n",
    "\n",
    "# make_predictions(USER_ID, NUM_RECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d5223",
   "metadata": {},
   "source": [
    "# Practice: Implementing LightGCN\n",
    "\n",
    "## Light Graph Convolution\n",
    "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
    "\n",
    "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
    "\n",
    "$e_u^{(k)}$ : k-th layer user embedding\n",
    "\n",
    "$e_i^{(k)}$ : k-th layer item embedding\n",
    "\n",
    "\n",
    "\n",
    "## Layer Combination and Model Prediction\n",
    "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}_{ui} = e_u^Te_i\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "4ef0ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim, n_layers, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.n_layers = embedding_dim, n_layers\n",
    "        self.add_self_loops = add_self_loops\n",
    "        \n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        users_emb_final, items_emb_final = None, None\n",
    "        ############################################################################\n",
    "        # TODO: Your code here!\n",
    "        # you can reference the previous NGCF implementation!\n",
    "        # Steps: \n",
    "        # 1. normalize edge weight \n",
    "        # 2. save embedding of each propagation\n",
    "        # 3. for simplicity, we take the average of embedding among different layers as the output\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
    "        # print(self.num_users)\n",
    "        # print(self.num_items)\n",
    "        # print(self.users_emb.weight.shape)  \n",
    "        # print(self.items_emb.weight.shape)\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "        # print(emb_k.shape)\n",
    "        for i in range(self.n_layers):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k, K=i)\n",
    "            embs.append(emb_k)\n",
    "        emb_final = torch.stack(embs, dim=0).sum(dim=0)\n",
    "        # print(emb_final.shape)\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items])\n",
    "        # print(users_emb_final.shape)\n",
    "        # print(items_emb_final.shape)\n",
    "        ############################################################################\n",
    "        return users_emb_final, items_emb_final\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        ############################################################################\n",
    "        # TODO: Your code here!\n",
    "        # define the message function here\n",
    "        \n",
    "        ############################################################################\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "dbf243a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "ITERS_PER_EVAL = 100\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "\n",
    "############################\n",
    "# TODO: Your code here!\n",
    "# chose the best hyperparameters!\n",
    "\n",
    "# hyperparameters\n",
    "N_LAYERS = 3\n",
    "LAMBDA = 1e-4\n",
    "DIM = 64\n",
    "LR = 0.001\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "6714b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "model = LightGCN(num_users, num_movies,embedding_dim=DIM,n_layers=N_LAYERS)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# initialize parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=LAMBDA)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb05d5",
   "metadata": {},
   "source": [
    "## Training!\n",
    "Let's see if your LightGCN outperforms NGCF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "efa6693e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: 0.8856, val_loss: 0.6932, val_recall@20: 0.0064, val_precision@20: 0.0014, val_ndcg@20: 0.0031\n",
      "[Iteration 100/10000] train_loss: 0.4103, val_loss: 0.6924, val_recall@20: 0.0091, val_precision@20: 0.0031, val_ndcg@20: 0.0061\n",
      "[Iteration 200/10000] train_loss: 0.3338, val_loss: 0.6908, val_recall@20: 0.0126, val_precision@20: 0.0046, val_ndcg@20: 0.0112\n",
      "[Iteration 300/10000] train_loss: 0.3541, val_loss: 0.6901, val_recall@20: 0.0101, val_precision@20: 0.0036, val_ndcg@20: 0.0070\n",
      "[Iteration 400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 500/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 700/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 900/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1100/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1300/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1500/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[650], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m ITERS_PER_EVAL \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 28\u001b[0m     val_loss, recall, precision, ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_sparse_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_edge_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mITERATIONS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_recall@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_precision@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_ndcg@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndcg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[638], line 30\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(model, edge_index, sparse_edge_index, exclude_edge_indices, k)\u001b[0m\n\u001b[1;32m     26\u001b[0m neg_items_emb_final \u001b[38;5;241m=\u001b[39m items_emb_final[neg_item_indices]\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 30\u001b[0m recall, precision, ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43musers_emb_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems_emb_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_edge_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, recall, precision, ndcg\n",
      "Cell \u001b[0;32mIn[637], line 47\u001b[0m, in \u001b[0;36mget_metrics\u001b[0;34m(user_embedding, item_embedding, edge_index, exclude_edge_indices, k)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m users:\n\u001b[1;32m     46\u001b[0m     ground_truth_items \u001b[38;5;241m=\u001b[39m test_user_pos_items[user\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m---> 47\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mground_truth_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_K_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     49\u001b[0m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray(r)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[637], line 47\u001b[0m, in \u001b[0;36mget_metrics.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m users:\n\u001b[1;32m     46\u001b[0m     ground_truth_items \u001b[38;5;241m=\u001b[39m test_user_pos_items[user\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m---> 47\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;129;01min\u001b[39;00m ground_truth_items, top_K_items[user]))\n\u001b[1;32m     48\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     49\u001b[0m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray(r)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, items_emb_final = model.forward(\n",
    "        train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final = users_emb_final[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {train_loss.item():.4f}, val_loss: {val_loss:.4f}, val_recall@{K}: {recall:.4f}, val_precision@{K}: {precision:.4f}, val_ndcg@{K}: {ndcg:.4f}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bc734",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
    "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K)\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
