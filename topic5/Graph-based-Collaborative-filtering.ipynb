{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4748fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "# !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
    "# !pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32ad5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44359c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movie_path = './ml-latest-small/movies.csv'\n",
    "rating_path = './ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1244d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user and movie nodes\n",
    "def load_node_csv(path, index_col):\n",
    "    \"\"\"Loads csv containing node information\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        index_col (str): column name of index column\n",
    "\n",
    "    Returns:\n",
    "        dict: mapping of csv row to node id\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, index_col=index_col)\n",
    "    \n",
    "    # assign unique index for each user/movie\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    return mapping\n",
    "\n",
    "\n",
    "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
    "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe36f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edges between users and movies\n",
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        src_index_col (str): column name of users\n",
    "        src_mapping (dict): mapping between row number and user id\n",
    "        dst_index_col (str): column name of items\n",
    "        dst_mapping (dict): mapping between row number and item id\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    edge_index = None\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "\n",
    "    return torch.tensor(edge_index)\n",
    "\n",
    "\n",
    "edge_index = load_edge_csv(\n",
    "    rating_path,\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f11250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
    "num_interactions = edge_index.shape[1]\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=1)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices, test_size=0.5, random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f7c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef229e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4175a90",
   "metadata": {},
   "source": [
    "# Implementing NGCF\n",
    "\n",
    "## High-order Propagation in NGCF\n",
    "Between each layer, NGCF uses the following propagation rule for user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "e_u^{(k)} = LeakyReLU \\left(  m^{(k)}_{u \\leftarrow u}  + \\sum_{i\\in N_u}   m^{(k)}_{u \\leftarrow i} \\right)\\\\\n",
    "m^{(k)}_{u \\leftarrow u} = W_1^{(k)}e_u^{(k-1)},\\\\\n",
    "m^{(k)}_{u \\leftarrow i} = \\frac{1}{\\sqrt{|N_u||N_i|}} \\left( W_1^{(k)}e_i^{(k-1)} + W_2^{(k)} \\left( e_i^{(k-1)} \\odot e_u^{(k-1)} \\right)  \\right)\n",
    "\\end{equation}\n",
    "\n",
    "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
    "\n",
    "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
    "\n",
    "$e_u^{(k)}$ : k-th layer user embedding\n",
    "\n",
    "$e_i^{(k)}$ : k-th layer item embedding\n",
    "\n",
    "\n",
    "\n",
    "## Layer Combination and Model Prediction\n",
    "We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "e_u = e_u^{(0)} || \\cdots || e_u^{(K)} \\quad e_i = e_i^{(0)} || \\cdots || e_i^{(K)}\n",
    "\\end{equation}\n",
    "\n",
    "$||$ : denotes the concatenate operation\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}_{ui} = e_u^Te_i\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f987b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines NGCF model\n",
    "class NGCF(MessagePassing):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes NGCF Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "        self.W1_list = nn.ModuleList([nn.Linear(self.embedding_dim,self.embedding_dim,bias=False) for _ in range(K)])\n",
    "        self.W2_list = nn.ModuleList([nn.Linear(self.embedding_dim,self.embedding_dim,bias=False) for _ in range(K)])\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of NGCF Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_i_k\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k, K=i) + self.W1_list[i](emb_k)\n",
    "            emb_k = F.leaky_relu(emb_k)\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        emb_final = torch.cat(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, items_emb_final\n",
    "\n",
    "    def message(self, x_i: Tensor, x_j: Tensor, K: int ) -> Tensor:\n",
    "        return self.W1_list[K](x_j) + self.W2_list[K](x_j * x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57e1f8",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "\n",
    "\n",
    "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
    "\n",
    "\\begin{equation}\n",
    "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
    "\\end{equation}\n",
    "\n",
    "$\\hat{y}_{u}$: predicted score of a positive sample\n",
    "\n",
    "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
    "\n",
    "$\\lambda$: hyperparameter which controls the L2 regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d4531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, pos_items_emb_final, neg_items_emb_final):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "    loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50a85c",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We evalaluate our model using the following metrics\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "p: a particular rank position\n",
    "\n",
    "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
    "\n",
    "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
    "\n",
    "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
    "\\end{equation}\n",
    "\n",
    "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fffb4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe36cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a08bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb3fcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(user_embedding, item_embedding, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35863d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    #users_emb_final, items_emb_final = model.forward(sparse_edge_index)\n",
    "    users_emb_final, items_emb_final = model.users_emb.weight, model.items_emb.weight\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    \n",
    "    # indices\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final = users_emb_final[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        users_emb_final, items_emb_final, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e9e16",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Your test set performance should be in line with the following (*K=20*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef072d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30fc7342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "model = NGCF(num_users, num_movies,embedding_dim=DIM)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# initialize parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=LAMBDA)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d24d235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: inf, val_loss: nan, val_recall@20: 0.0184, val_precision@20: 0.0068, val_ndcg@20: 0.0135\n",
      "[Iteration 200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 1800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 2000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 2200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 2400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 2600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 2800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 3000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 3200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 3400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 3600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 3800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 4000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 4200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 4400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 4600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 4800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 5000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 5200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 5400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 5600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 5800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 6000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 6200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 6400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 6600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 6800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 7000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 7200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 7400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 7600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 7800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 8000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 8200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 8400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 8600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 8800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 9000/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 9200/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 9400/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 9600/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n",
      "[Iteration 9800/10000] train_loss: nan, val_loss: nan, val_recall@20: 0.0180, val_precision@20: 0.0070, val_ndcg@20: 0.0121\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, items_emb_final = model.forward(\n",
    "        train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final = users_emb_final[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, pos_items_emb_final, neg_items_emb_final)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {train_loss.item():.4f}, val_loss: {val_loss:.4f}, val_recall@{K}: {recall:.4f}, val_precision@{K}: {precision:.4f}, val_ndcg@{K}: {ndcg:.4f}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd793e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b8ecada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss: nan, test_recall@20: 0.02381, test_precision@20: 0.00679, test_ndcg@20: 0.01547\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
    "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K)\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e3c0a",
   "metadata": {},
   "source": [
    "# Make New Recommendatios for a Given User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fdea58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "df = pd.read_csv(movie_path)\n",
    "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
    "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
    "\n",
    "user_pos_items = get_user_positive_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33bbb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(user_id, num_recs):\n",
    "    user = user_mapping[user_id]\n",
    "    e_u = model.users_emb.weight[user]\n",
    "    scores = model.items_emb.weight @ e_u\n",
    "\n",
    "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
    "\n",
    "    print()\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some suggested movies for user {user_id}\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e3f97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some movies that user 6 rated highly\n",
      "title: Jumanji (1995), genres: Adventure|Children|Fantasy \n",
      "title: Grumpier Old Men (1995), genres: Comedy|Romance \n",
      "title: Father of the Bride Part II (1995), genres: Comedy \n",
      "title: Heat (1995), genres: Action|Crime|Thriller \n",
      "\n",
      "Here are some suggested movies for user 6\n",
      "title: Toy Story (1995), genres: Adventure|Animation|Children|Comedy|Fantasy \n",
      "title: Waiting to Exhale (1995), genres: Comedy|Drama|Romance \n",
      "title: Tom and Huck (1995), genres: Adventure|Children \n",
      "title: Sudden Death (1995), genres: Action \n"
     ]
    }
   ],
   "source": [
    "USER_ID = 6\n",
    "NUM_RECS = 4\n",
    "\n",
    "make_predictions(USER_ID, NUM_RECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d5223",
   "metadata": {},
   "source": [
    "# Practice: Implementing LightGCN\n",
    "\n",
    "## Light Graph Convolution\n",
    "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
    "\n",
    "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
    "\n",
    "$e_u^{(k)}$ : k-th layer user embedding\n",
    "\n",
    "$e_i^{(k)}$ : k-th layer item embedding\n",
    "\n",
    "\n",
    "\n",
    "## Layer Combination and Model Prediction\n",
    "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}_{ui} = e_u^Te_i\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef0ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim, n_layers, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.n_layers = embedding_dim, n_layers\n",
    "        self.add_self_loops = add_self_loops\n",
    "        \n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        users_emb_final, items_emb_final = None, None\n",
    "        ############################################################################\n",
    "        # TODO: Your code here!\n",
    "        # you can reference the previous NGCF implementation!\n",
    "        # Steps: \n",
    "        # 1. normalize edge weight \n",
    "        # 2. save embedding of each propagation\n",
    "        # 3. for simplicity, we take the average of embedding among different layers as the output\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "        for i in range(self.n_layers):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k, K=i)\n",
    "            embs.append(emb_k)\n",
    "        emb_final = torch.stack(embs, dim=0).sum(dim=0)\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items])\n",
    "        ############################################################################\n",
    "        return users_emb_final, items_emb_final\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        ############################################################################\n",
    "        # TODO: Your code here!\n",
    "        # define the message function here\n",
    "        \n",
    "        ############################################################################\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf243a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "ITERS_PER_EVAL = 100\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "\n",
    "############################\n",
    "# TODO: Your code here!\n",
    "# chose the best hyperparameters!\n",
    "\n",
    "# hyperparameters\n",
    "N_LAYERS = 3\n",
    "LAMBDA = 1e-4\n",
    "DIM = 64\n",
    "LR = 0.001\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6714b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "model = LightGCN(num_users, num_movies,embedding_dim=DIM,n_layers=N_LAYERS)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# initialize parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=LAMBDA)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb05d5",
   "metadata": {},
   "source": [
    "## Training!\n",
    "Let's see if your LightGCN outperforms NGCF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efa6693e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: 1.7357, val_loss: 0.6931, val_recall@20: 0.0016, val_precision@20: 0.0005, val_ndcg@20: 0.0011\n",
      "[Iteration 100/10000] train_loss: 0.3272, val_loss: 0.6931, val_recall@20: 0.0102, val_precision@20: 0.0039, val_ndcg@20: 0.0075\n",
      "[Iteration 200/10000] train_loss: 0.2611, val_loss: 0.6931, val_recall@20: 0.0128, val_precision@20: 0.0047, val_ndcg@20: 0.0087\n",
      "[Iteration 300/10000] train_loss: 0.2795, val_loss: 0.6931, val_recall@20: 0.0152, val_precision@20: 0.0063, val_ndcg@20: 0.0102\n",
      "[Iteration 400/10000] train_loss: 0.1953, val_loss: 0.6934, val_recall@20: 0.0126, val_precision@20: 0.0058, val_ndcg@20: 0.0113\n",
      "[Iteration 500/10000] train_loss: 0.2877, val_loss: 0.6933, val_recall@20: 0.0132, val_precision@20: 0.0060, val_ndcg@20: 0.0110\n",
      "[Iteration 600/10000] train_loss: 0.1944, val_loss: 0.6935, val_recall@20: 0.0141, val_precision@20: 0.0052, val_ndcg@20: 0.0097\n",
      "[Iteration 700/10000] train_loss: 0.1762, val_loss: 0.6935, val_recall@20: 0.0158, val_precision@20: 0.0059, val_ndcg@20: 0.0111\n",
      "[Iteration 800/10000] train_loss: 0.1807, val_loss: 0.6936, val_recall@20: 0.0151, val_precision@20: 0.0058, val_ndcg@20: 0.0100\n",
      "[Iteration 900/10000] train_loss: 0.1711, val_loss: 0.6936, val_recall@20: 0.0152, val_precision@20: 0.0057, val_ndcg@20: 0.0105\n",
      "[Iteration 1000/10000] train_loss: 0.1272, val_loss: 0.6936, val_recall@20: 0.0143, val_precision@20: 0.0047, val_ndcg@20: 0.0094\n",
      "[Iteration 1100/10000] train_loss: 0.1209, val_loss: 0.6938, val_recall@20: 0.0156, val_precision@20: 0.0053, val_ndcg@20: 0.0105\n",
      "[Iteration 1200/10000] train_loss: 0.1429, val_loss: 0.6936, val_recall@20: 0.0144, val_precision@20: 0.0051, val_ndcg@20: 0.0089\n",
      "[Iteration 1300/10000] train_loss: 0.1324, val_loss: 0.6938, val_recall@20: 0.0187, val_precision@20: 0.0052, val_ndcg@20: 0.0120\n",
      "[Iteration 1400/10000] train_loss: 0.1219, val_loss: 0.6938, val_recall@20: 0.0185, val_precision@20: 0.0052, val_ndcg@20: 0.0120\n",
      "[Iteration 1500/10000] train_loss: 0.0904, val_loss: 0.6937, val_recall@20: 0.0178, val_precision@20: 0.0053, val_ndcg@20: 0.0118\n",
      "[Iteration 1600/10000] train_loss: 0.1079, val_loss: 0.6939, val_recall@20: 0.0153, val_precision@20: 0.0053, val_ndcg@20: 0.0102\n",
      "[Iteration 1700/10000] train_loss: 0.1040, val_loss: 0.6938, val_recall@20: 0.0157, val_precision@20: 0.0056, val_ndcg@20: 0.0113\n",
      "[Iteration 1800/10000] train_loss: 0.0895, val_loss: 0.6939, val_recall@20: 0.0145, val_precision@20: 0.0048, val_ndcg@20: 0.0102\n",
      "[Iteration 1900/10000] train_loss: 0.0858, val_loss: 0.6941, val_recall@20: 0.0127, val_precision@20: 0.0049, val_ndcg@20: 0.0092\n",
      "[Iteration 2000/10000] train_loss: 0.0712, val_loss: 0.6938, val_recall@20: 0.0171, val_precision@20: 0.0052, val_ndcg@20: 0.0109\n",
      "[Iteration 2100/10000] train_loss: 0.1178, val_loss: 0.6941, val_recall@20: 0.0168, val_precision@20: 0.0061, val_ndcg@20: 0.0110\n",
      "[Iteration 2200/10000] train_loss: 0.0853, val_loss: 0.6939, val_recall@20: 0.0166, val_precision@20: 0.0056, val_ndcg@20: 0.0107\n",
      "[Iteration 2300/10000] train_loss: 0.0830, val_loss: 0.6941, val_recall@20: 0.0132, val_precision@20: 0.0053, val_ndcg@20: 0.0101\n",
      "[Iteration 2400/10000] train_loss: 0.0771, val_loss: 0.6940, val_recall@20: 0.0140, val_precision@20: 0.0052, val_ndcg@20: 0.0094\n",
      "[Iteration 2500/10000] train_loss: 0.0643, val_loss: 0.6940, val_recall@20: 0.0186, val_precision@20: 0.0054, val_ndcg@20: 0.0111\n",
      "[Iteration 2600/10000] train_loss: 0.0617, val_loss: 0.6942, val_recall@20: 0.0205, val_precision@20: 0.0056, val_ndcg@20: 0.0141\n",
      "[Iteration 2700/10000] train_loss: 0.1027, val_loss: 0.6941, val_recall@20: 0.0205, val_precision@20: 0.0058, val_ndcg@20: 0.0137\n",
      "[Iteration 2800/10000] train_loss: 0.0944, val_loss: 0.6939, val_recall@20: 0.0190, val_precision@20: 0.0062, val_ndcg@20: 0.0126\n",
      "[Iteration 2900/10000] train_loss: 0.0571, val_loss: 0.6943, val_recall@20: 0.0151, val_precision@20: 0.0055, val_ndcg@20: 0.0119\n",
      "[Iteration 3000/10000] train_loss: 0.0669, val_loss: 0.6941, val_recall@20: 0.0172, val_precision@20: 0.0047, val_ndcg@20: 0.0109\n",
      "[Iteration 3100/10000] train_loss: 0.0842, val_loss: 0.6942, val_recall@20: 0.0196, val_precision@20: 0.0056, val_ndcg@20: 0.0132\n",
      "[Iteration 3200/10000] train_loss: 0.0617, val_loss: 0.6942, val_recall@20: 0.0200, val_precision@20: 0.0053, val_ndcg@20: 0.0120\n",
      "[Iteration 3300/10000] train_loss: 0.0549, val_loss: 0.6944, val_recall@20: 0.0197, val_precision@20: 0.0056, val_ndcg@20: 0.0112\n",
      "[Iteration 3400/10000] train_loss: 0.0517, val_loss: 0.6943, val_recall@20: 0.0170, val_precision@20: 0.0058, val_ndcg@20: 0.0107\n",
      "[Iteration 3500/10000] train_loss: 0.0655, val_loss: 0.6942, val_recall@20: 0.0156, val_precision@20: 0.0051, val_ndcg@20: 0.0105\n",
      "[Iteration 3600/10000] train_loss: 0.0467, val_loss: 0.6943, val_recall@20: 0.0157, val_precision@20: 0.0052, val_ndcg@20: 0.0107\n",
      "[Iteration 3700/10000] train_loss: 0.0601, val_loss: 0.6942, val_recall@20: 0.0170, val_precision@20: 0.0058, val_ndcg@20: 0.0109\n",
      "[Iteration 3800/10000] train_loss: 0.0502, val_loss: 0.6941, val_recall@20: 0.0172, val_precision@20: 0.0054, val_ndcg@20: 0.0114\n",
      "[Iteration 3900/10000] train_loss: 0.0804, val_loss: 0.6942, val_recall@20: 0.0178, val_precision@20: 0.0054, val_ndcg@20: 0.0113\n",
      "[Iteration 4000/10000] train_loss: 0.0560, val_loss: 0.6943, val_recall@20: 0.0140, val_precision@20: 0.0058, val_ndcg@20: 0.0103\n",
      "[Iteration 4100/10000] train_loss: 0.0553, val_loss: 0.6943, val_recall@20: 0.0174, val_precision@20: 0.0061, val_ndcg@20: 0.0121\n",
      "[Iteration 4200/10000] train_loss: 0.0657, val_loss: 0.6941, val_recall@20: 0.0175, val_precision@20: 0.0063, val_ndcg@20: 0.0120\n",
      "[Iteration 4300/10000] train_loss: 0.0544, val_loss: 0.6943, val_recall@20: 0.0180, val_precision@20: 0.0060, val_ndcg@20: 0.0119\n",
      "[Iteration 4400/10000] train_loss: 0.0764, val_loss: 0.6943, val_recall@20: 0.0180, val_precision@20: 0.0058, val_ndcg@20: 0.0109\n",
      "[Iteration 4500/10000] train_loss: 0.0651, val_loss: 0.6942, val_recall@20: 0.0160, val_precision@20: 0.0052, val_ndcg@20: 0.0106\n",
      "[Iteration 4600/10000] train_loss: 0.0574, val_loss: 0.6943, val_recall@20: 0.0150, val_precision@20: 0.0054, val_ndcg@20: 0.0103\n",
      "[Iteration 4700/10000] train_loss: 0.0731, val_loss: 0.6943, val_recall@20: 0.0164, val_precision@20: 0.0057, val_ndcg@20: 0.0114\n",
      "[Iteration 4800/10000] train_loss: 0.0499, val_loss: 0.6944, val_recall@20: 0.0195, val_precision@20: 0.0060, val_ndcg@20: 0.0116\n",
      "[Iteration 4900/10000] train_loss: 0.0689, val_loss: 0.6942, val_recall@20: 0.0169, val_precision@20: 0.0055, val_ndcg@20: 0.0108\n",
      "[Iteration 5000/10000] train_loss: 0.0504, val_loss: 0.6944, val_recall@20: 0.0145, val_precision@20: 0.0053, val_ndcg@20: 0.0108\n",
      "[Iteration 5100/10000] train_loss: 0.0347, val_loss: 0.6944, val_recall@20: 0.0192, val_precision@20: 0.0058, val_ndcg@20: 0.0118\n",
      "[Iteration 5200/10000] train_loss: 0.0629, val_loss: 0.6944, val_recall@20: 0.0188, val_precision@20: 0.0060, val_ndcg@20: 0.0112\n",
      "[Iteration 5300/10000] train_loss: 0.0511, val_loss: 0.6943, val_recall@20: 0.0185, val_precision@20: 0.0059, val_ndcg@20: 0.0109\n",
      "[Iteration 5400/10000] train_loss: 0.0395, val_loss: 0.6944, val_recall@20: 0.0165, val_precision@20: 0.0052, val_ndcg@20: 0.0105\n",
      "[Iteration 5500/10000] train_loss: 0.0493, val_loss: 0.6943, val_recall@20: 0.0173, val_precision@20: 0.0056, val_ndcg@20: 0.0107\n",
      "[Iteration 5600/10000] train_loss: 0.0506, val_loss: 0.6944, val_recall@20: 0.0165, val_precision@20: 0.0052, val_ndcg@20: 0.0101\n",
      "[Iteration 5700/10000] train_loss: 0.0439, val_loss: 0.6942, val_recall@20: 0.0161, val_precision@20: 0.0052, val_ndcg@20: 0.0100\n",
      "[Iteration 5800/10000] train_loss: 0.0537, val_loss: 0.6944, val_recall@20: 0.0163, val_precision@20: 0.0051, val_ndcg@20: 0.0095\n",
      "[Iteration 5900/10000] train_loss: 0.0454, val_loss: 0.6944, val_recall@20: 0.0142, val_precision@20: 0.0048, val_ndcg@20: 0.0093\n",
      "[Iteration 6000/10000] train_loss: 0.0632, val_loss: 0.6943, val_recall@20: 0.0167, val_precision@20: 0.0057, val_ndcg@20: 0.0105\n",
      "[Iteration 6100/10000] train_loss: 0.0365, val_loss: 0.6942, val_recall@20: 0.0167, val_precision@20: 0.0059, val_ndcg@20: 0.0110\n",
      "[Iteration 6200/10000] train_loss: 0.0457, val_loss: 0.6944, val_recall@20: 0.0202, val_precision@20: 0.0059, val_ndcg@20: 0.0124\n",
      "[Iteration 6300/10000] train_loss: 0.0427, val_loss: 0.6944, val_recall@20: 0.0184, val_precision@20: 0.0058, val_ndcg@20: 0.0117\n",
      "[Iteration 6400/10000] train_loss: 0.0665, val_loss: 0.6944, val_recall@20: 0.0168, val_precision@20: 0.0058, val_ndcg@20: 0.0114\n",
      "[Iteration 6500/10000] train_loss: 0.0306, val_loss: 0.6943, val_recall@20: 0.0194, val_precision@20: 0.0060, val_ndcg@20: 0.0125\n",
      "[Iteration 6600/10000] train_loss: 0.0359, val_loss: 0.6944, val_recall@20: 0.0183, val_precision@20: 0.0061, val_ndcg@20: 0.0126\n",
      "[Iteration 6700/10000] train_loss: 0.0436, val_loss: 0.6944, val_recall@20: 0.0162, val_precision@20: 0.0052, val_ndcg@20: 0.0104\n",
      "[Iteration 6800/10000] train_loss: 0.0421, val_loss: 0.6944, val_recall@20: 0.0137, val_precision@20: 0.0047, val_ndcg@20: 0.0099\n",
      "[Iteration 6900/10000] train_loss: 0.0362, val_loss: 0.6944, val_recall@20: 0.0145, val_precision@20: 0.0042, val_ndcg@20: 0.0094\n",
      "[Iteration 7000/10000] train_loss: 0.0510, val_loss: 0.6945, val_recall@20: 0.0158, val_precision@20: 0.0045, val_ndcg@20: 0.0099\n",
      "[Iteration 7100/10000] train_loss: 0.0559, val_loss: 0.6944, val_recall@20: 0.0155, val_precision@20: 0.0049, val_ndcg@20: 0.0099\n",
      "[Iteration 7200/10000] train_loss: 0.0433, val_loss: 0.6944, val_recall@20: 0.0137, val_precision@20: 0.0046, val_ndcg@20: 0.0093\n",
      "[Iteration 7300/10000] train_loss: 0.0303, val_loss: 0.6944, val_recall@20: 0.0147, val_precision@20: 0.0051, val_ndcg@20: 0.0099\n",
      "[Iteration 7400/10000] train_loss: 0.0480, val_loss: 0.6943, val_recall@20: 0.0131, val_precision@20: 0.0048, val_ndcg@20: 0.0095\n",
      "[Iteration 7500/10000] train_loss: 0.0434, val_loss: 0.6944, val_recall@20: 0.0130, val_precision@20: 0.0044, val_ndcg@20: 0.0090\n",
      "[Iteration 7600/10000] train_loss: 0.0262, val_loss: 0.6943, val_recall@20: 0.0124, val_precision@20: 0.0045, val_ndcg@20: 0.0089\n",
      "[Iteration 7700/10000] train_loss: 0.0553, val_loss: 0.6945, val_recall@20: 0.0111, val_precision@20: 0.0042, val_ndcg@20: 0.0086\n",
      "[Iteration 7800/10000] train_loss: 0.0407, val_loss: 0.6944, val_recall@20: 0.0123, val_precision@20: 0.0045, val_ndcg@20: 0.0092\n",
      "[Iteration 7900/10000] train_loss: 0.0382, val_loss: 0.6944, val_recall@20: 0.0135, val_precision@20: 0.0050, val_ndcg@20: 0.0095\n",
      "[Iteration 8000/10000] train_loss: 0.0328, val_loss: 0.6944, val_recall@20: 0.0133, val_precision@20: 0.0047, val_ndcg@20: 0.0097\n",
      "[Iteration 8100/10000] train_loss: 0.0466, val_loss: 0.6944, val_recall@20: 0.0118, val_precision@20: 0.0047, val_ndcg@20: 0.0088\n",
      "[Iteration 8200/10000] train_loss: 0.0402, val_loss: 0.6944, val_recall@20: 0.0120, val_precision@20: 0.0046, val_ndcg@20: 0.0094\n",
      "[Iteration 8300/10000] train_loss: 0.0373, val_loss: 0.6942, val_recall@20: 0.0108, val_precision@20: 0.0043, val_ndcg@20: 0.0088\n",
      "[Iteration 8400/10000] train_loss: 0.0384, val_loss: 0.6944, val_recall@20: 0.0120, val_precision@20: 0.0045, val_ndcg@20: 0.0091\n",
      "[Iteration 8500/10000] train_loss: 0.0371, val_loss: 0.6944, val_recall@20: 0.0106, val_precision@20: 0.0043, val_ndcg@20: 0.0085\n",
      "[Iteration 8600/10000] train_loss: 0.0383, val_loss: 0.6944, val_recall@20: 0.0094, val_precision@20: 0.0041, val_ndcg@20: 0.0079\n",
      "[Iteration 8700/10000] train_loss: 0.0314, val_loss: 0.6944, val_recall@20: 0.0120, val_precision@20: 0.0043, val_ndcg@20: 0.0086\n",
      "[Iteration 8800/10000] train_loss: 0.0333, val_loss: 0.6944, val_recall@20: 0.0135, val_precision@20: 0.0044, val_ndcg@20: 0.0093\n",
      "[Iteration 8900/10000] train_loss: 0.0329, val_loss: 0.6942, val_recall@20: 0.0117, val_precision@20: 0.0044, val_ndcg@20: 0.0088\n",
      "[Iteration 9000/10000] train_loss: 0.0276, val_loss: 0.6943, val_recall@20: 0.0142, val_precision@20: 0.0045, val_ndcg@20: 0.0095\n",
      "[Iteration 9100/10000] train_loss: 0.0305, val_loss: 0.6944, val_recall@20: 0.0131, val_precision@20: 0.0046, val_ndcg@20: 0.0094\n",
      "[Iteration 9200/10000] train_loss: 0.0274, val_loss: 0.6944, val_recall@20: 0.0146, val_precision@20: 0.0045, val_ndcg@20: 0.0096\n",
      "[Iteration 9300/10000] train_loss: 0.0289, val_loss: 0.6944, val_recall@20: 0.0148, val_precision@20: 0.0049, val_ndcg@20: 0.0098\n",
      "[Iteration 9400/10000] train_loss: 0.0371, val_loss: 0.6944, val_recall@20: 0.0130, val_precision@20: 0.0048, val_ndcg@20: 0.0096\n",
      "[Iteration 9500/10000] train_loss: 0.0466, val_loss: 0.6944, val_recall@20: 0.0119, val_precision@20: 0.0047, val_ndcg@20: 0.0094\n",
      "[Iteration 9600/10000] train_loss: 0.0361, val_loss: 0.6943, val_recall@20: 0.0131, val_precision@20: 0.0044, val_ndcg@20: 0.0096\n",
      "[Iteration 9700/10000] train_loss: 0.0294, val_loss: 0.6944, val_recall@20: 0.0130, val_precision@20: 0.0043, val_ndcg@20: 0.0092\n",
      "[Iteration 9800/10000] train_loss: 0.0334, val_loss: 0.6945, val_recall@20: 0.0129, val_precision@20: 0.0043, val_ndcg@20: 0.0090\n",
      "[Iteration 9900/10000] train_loss: 0.0379, val_loss: 0.6943, val_recall@20: 0.0151, val_precision@20: 0.0046, val_ndcg@20: 0.0096\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, items_emb_final = model.forward(\n",
    "        train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final = users_emb_final[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {train_loss.item():.4f}, val_loss: {val_loss:.4f}, val_recall@{K}: {recall:.4f}, val_precision@{K}: {precision:.4f}, val_ndcg@{K}: {ndcg:.4f}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c7bc734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c35e4be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss: 0.69407, test_recall@20: 0.01426, test_precision@20: 0.00607, test_ndcg@20: 0.01027\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
    "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K)\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
